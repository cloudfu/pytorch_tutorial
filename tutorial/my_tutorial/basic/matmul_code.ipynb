{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch 乘法运算汇总与解析\n",
    "https://www.jianshu.com/p/de4b6f67051f  \n",
    "具体详见连接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 元素相乘\n",
    "该操作又称作 \"哈达玛积\", 简单来说就是 tensor 元素逐个相乘。这个操作，是通过 * 也就是常规的乘号操作符定义的操作结果。torch.mul 是等价的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 4, 10, 18]), tensor([ 4, 10, 18]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# mul 和 * 一致，按照元素位置进行相乘，不做降维\n",
    "def element_by_element():\n",
    "    \n",
    "    x = torch.tensor([1, 2, 3])\n",
    "    y = torch.tensor([4, 5, 6])\n",
    "    \n",
    "    return x * y, torch.mul(x, y)\n",
    "\n",
    "element_by_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# 向量和标量相乘，会进行broadcast进行广播\n",
    "def element_by_element_broadcast():    \n",
    "    x = torch.tensor([1, 2, 3])\n",
    "    y = 2\n",
    "    return x * y\n",
    "\n",
    "element_by_element_broadcast()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量点乘\n",
    "torch.matmul: If both tensors are 1-dimensional, the dot product (scalar) is returned.\n",
    "<BR/>如果都是1维的，返回的就是 dot product 结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# 向量matmul 点积按照维度相乘之后再相加，会进行降维处理\n",
    "def vec_dot_product():\n",
    "    \n",
    "    x = torch.tensor([1, 2, 3])\n",
    "    y = torch.tensor([4, 5, 6])\n",
    "    \n",
    "    return torch.matmul(x, y)\n",
    "vec_dot_product()\n",
    "# tensor(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵乘法\n",
    "torch.matmul: If both arguments are 2-dimensional, the matrix-matrix product is returned.\n",
    "<BR/>如果都是2维，那么就是矩阵乘法的结果返回。与 torch.mm 是等价的，torch.mm 仅仅能处理的是矩阵乘法。\n",
    "<BR/>\n",
    "![avatar](./img/numpy.dot.png)  \n",
    "![avatar](./img/matmul.jpg)   \n",
    "<font color=yellow>\n",
    "第一个matrix的行（一维）决定输出单元格的行数（一维）  \n",
    "第二个matrix的列（二维）决定了输出单元格列数（二维）   \n",
    "第一个矩阵：列决定行，第二矩阵：行决定列，行列相乘再相加\n",
    "</font>\n",
    "\n",
    "如果是二维数组（矩阵）之间的运算，则得到的是矩阵积（mastrix product）。\n",
    "所得到的数组中的每个元素为，第一个矩阵中与该元素行号相同的元素与第二个矩阵与该元素列号相同的元素，两两相乘后再求和。\n",
    "这句话有点难理解，但是这句话里面没有哪个字是多余的。结合下图理解这句话。\n",
    "<BR>\n",
    "mm 只能使用在二维矩阵 matmul可以使用多为矩阵相乘\n",
    "\n",
    "<br/>\n",
    "解释：\n",
    "    x = torch.tensor([\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1]\n",
    "    ])\n",
    "    y = torch.tensor([\n",
    "        [2, 2],\n",
    "        [2, 2],\n",
    "        [2, 3]\n",
    "    ])\n",
    "<br/>\n",
    "x 先使用第1行和 y 的第1列相乘，得到新matrix [Update,0][0,0]数据，和y相乘的列决定了当前列的位置，即为0 \n",
    "<br/>\n",
    "x 先使用第1行和 y 的第2列相乘，得到新matrix [0,Update][0,0]数据，和y相乘的列决定了当前列的位置，即为1\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [4, 5, 6],\n",
      "        [6, 7, 8]])\n",
      "tensor([[1, 4, 7],\n",
      "        [2, 5, 8],\n",
      "        [3, 6, 9]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 30,  36,  42],\n",
       "         [ 66,  81,  96],\n",
       "         [ 66,  81,  96],\n",
       "         [ 90, 111, 132]]),\n",
       " tensor([[ 30,  36,  42],\n",
       "         [ 66,  81,  96],\n",
       "         [ 66,  81,  96],\n",
       "         [ 90, 111, 132]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# tensor([[1, 2, 3],\n",
    "#         [4, 5, 6]])\n",
    "# y = torch.tensor([\n",
    "#      [7, 8],\n",
    "#      [9, 10],\n",
    "#      [11, 12]\n",
    "# ])\n",
    "\n",
    "# 理解1，如上图\n",
    "# x = (a,b) \n",
    "# y = (b,c) \n",
    "# x * y= (a,c)\n",
    "# 计算过程：\n",
    "# a[0] = 1*7 + 2*9 + 3*11 = 58\n",
    "# a[1] = 1*8 + 2*10 + 3*12 = 64\n",
    "\n",
    "\n",
    "# 理解2\n",
    "# x = (2,3) (a,b)\n",
    "# y = (3,2) (c,d)\n",
    "# y = y.transpose(0,1) -> (2,3)\n",
    "# x * y = (a*c,a*d),(b*c,b*d) 行之间进行乘法和加法求和\n",
    "\n",
    "\n",
    "\n",
    "def matrix_multiple():\n",
    "    \n",
    "    x = torch.tensor([\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [4, 5, 6],\n",
    "        [6, 7, 8]\n",
    "    ])\n",
    "    print(x)\n",
    "    \n",
    "    y = torch.tensor([\n",
    "        [1, 2,3],\n",
    "        [4, 5,6],\n",
    "        [7, 8,9]\n",
    "    ])\n",
    "    # print(y)\n",
    "    print(y.T)\n",
    "    # 转置之后 是通过\n",
    "\n",
    "    \n",
    "    return torch.matmul(x, y), torch.mm(x, y)\n",
    "\n",
    "matrix_multiple()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vector 与 matrix 相乘\n",
    "torch.matmul: If the first argument is 1-dimensional and the second argument is 2-dimensional, a 1 is prepended to its dimension for the purpose of the matrix multiply. After the matrix multiply, the prepended dimension is removed.\n",
    "\n",
    "如果第一个是 vector, 第二个是 matrix, 会在 vector 中增加一个维度。也就是 vector 变成了  与 matrix  相乘之后，变成 , 在结果中将  维 再去掉。\n",
    "\n",
    "<font color=yellow>\n",
    "vector 与 matrix 相乘 \n",
    "vector 增加第一维度，后续按照标准规则进行\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([58, 64,  6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# (1,3) * (3,2) = (1,2)\n",
    "# 但是matmul(x,y)不能进行位置互换，需要满足 行列相同原则\n",
    "\n",
    "# torch.matmul(a, b)\n",
    "# a 决定输出行 b 决定输出列\n",
    "\n",
    "def vec_matrix():\n",
    "    x = torch.tensor([1, 2, 3])\n",
    "    y = torch.tensor([\n",
    "        [7, 8, 1],\n",
    "        [9, 10, 1],\n",
    "        [11, 12, 1]\n",
    "    ])\n",
    "\n",
    "# operation process:\n",
    "# 7 + 18 + 33 = 58\n",
    "# 8 + 20 + 36 = 64\n",
    "    \n",
    "    return torch.matmul(x, y)\n",
    "\n",
    "vec_matrix()\n",
    "# tensor([58, 64,  6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix 与 vector 相乘\n",
    "同样的道理， vector会被扩充一个维度。  \n",
    "<font color=yellow>\n",
    "matrix 与 vector 相乘\n",
    "vector 增加第二维度，满足 行列相同原则，之后进行行列相同累计；   \n",
    "</font>\n",
    "<font color=yellow>\n",
    "如果需要matrix降维，可以乘一个向量   \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 32,  74, 116, 158])\n",
      "tensor([10, 11])\n",
      "tensor([ 32,  74, 116, 158])\n",
      "tensor([[10, 22],\n",
      "        [30, 44],\n",
      "        [50, 66],\n",
      "        [70, 88]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# matrix 和 vector不相同\n",
    "def matrix_vec_unmatch():\n",
    "    x = torch.tensor([\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6]\n",
    "    ])\n",
    "    \n",
    "    y = torch.tensor([\n",
    "        7, 8, 9\n",
    "    ])\n",
    "\n",
    "    # 计算过程\n",
    "    # 将y空充维度[3] -> [3,1]:[[[[7,8,9]]]]???\n",
    "    \n",
    "    # 1*7 + 2*8 + 3*9 = 50\n",
    "    # 4*7 + 5*8 + 3*9 = 122\n",
    "    return torch.matmul(x, y)\n",
    "\n",
    "matrix_vec_unmatch()\n",
    "# tensor([ 50, 122])\n",
    "\n",
    "\n",
    "# 1.将y进行填充变成:y=[[7],[8]]，因为需要保持和x的二维大小相同，此时 y.shape = (3,1)\n",
    "# 2. 进行行列相乘，相加，即：\n",
    "#    1*10 + 2*11 = 32\n",
    "#    3*10 + 4*11 = 74\n",
    "#    5*10 + 6*11 = 116\n",
    "#    7*10 + 8*11 = 158\n",
    "# 生成数组[[32],[74],[116],[158]] = (4,1)，再去掉维度即[4]\n",
    "# 第一矩阵决定行，第二矩阵决定列的定义没有变化，只是进行维度扩充结算，之后再结果中进行了缩减；\n",
    "def matrix_vec_match():\n",
    "    x = torch.tensor([\n",
    "        [1, 2],\n",
    "        [3, 4],\n",
    "        [5, 6],\n",
    "        [7, 8]\n",
    "    ])\n",
    "    \n",
    "    y = torch.tensor([\n",
    "        10, 11\n",
    "    ])\n",
    "    \n",
    "    # 1*7 + 2*8 = 23\n",
    "    # 4*7 + 5*8 = 68\n",
    "    return torch.matmul(x,y)\n",
    "    # tensor([ 44,  86, 128, 170])\n",
    "\n",
    "# print(matrix_vec_match())\n",
    "# tensor([ 32,  74, 116, 158])\n",
    "\n",
    "x = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6],\n",
    "    [7, 8]\n",
    "])\n",
    "\n",
    "y = torch.tensor([\n",
    "    10, 11\n",
    "])\n",
    "print(y.T)\n",
    "\n",
    "y_1 = torch.tensor([\n",
    "    10, 11\n",
    "])\n",
    "\n",
    "# print(x @ y)\n",
    "# print(x * y_1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce539a29b37cbf6656fb94dad7e012f544b2b648a7f96b4739717121bbe2a2ab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
